{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XOPcHXXhAYn","outputId":"8e65085e-57c6-4502-adaf-c360cd38e636","executionInfo":{"status":"ok","timestamp":1702266526215,"user_tz":480,"elapsed":20582,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n","\n","# ...\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","source":["%cd /content/drive/Shared drives/Machine Learning/Recommendation Project/Guest User/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FOPE3bIiBl8","outputId":"ac3c6aea-28a1-4f76-cc73-de03fa4032f4","executionInfo":{"status":"ok","timestamp":1702266538237,"user_tz":480,"elapsed":1007,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shared drives/Machine Learning/Recommendation Project/Guest User\n"]}]},{"cell_type":"markdown","source":["### Load and Review the Products Data"],"metadata":{"id":"oaUpOx8zwi1Y"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# List of encodings to try\n","encodings_to_try = ['utf-8', 'ISO-8859-1', 'latin1']\n","\n","# Try reading the CSV file with different encodings\n","for encoding in encodings_to_try:\n","    try:\n","        df = pd.read_csv('Labeled_Products_2018.csv', encoding=encoding)\n","        # If reading is successful, break out of the loop\n","        break\n","    except UnicodeDecodeError:\n","        continue\n","\n","# Display the first few rows of the DataFrame to inspect the data.\n","print(df.columns)\n","# Display counts of each column\n","column_counts = df.count()\n","print(\"\\nCounts of Each Column:\")\n","print(column_counts)\n","df.head"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3koWgWeLiMNF","outputId":"42899a98-d637-4810-c0e0-d4ccccb3f27b","executionInfo":{"status":"ok","timestamp":1702266845597,"user_tz":480,"elapsed":429,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['asin', 'title', 'description', 'price', 'first_imageURLHighRes',\n","       'Summary', 'year', 'Category'],\n","      dtype='object')\n","\n","Counts of Each Column:\n","asin                     4530\n","title                    4530\n","description              4530\n","price                    4530\n","first_imageURLHighRes    4530\n","Summary                  4530\n","year                     4530\n","Category                 4530\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["<bound method NDFrame.head of             asin                                              title  \\\n","0     B00004U9V2  Crabtree &amp; Evelyn - Gardener's Ultra-Moist...   \n","1     B00005A77F  Crabtree &amp; Evelyn Hand Soap, Gardeners, 10...   \n","2     B00005NDTD                                 Soy Milk Hand Crme   \n","3     B00005V50C                     Supersmile Powdered Mouthrinse   \n","4     B00005V50B  Supersmile Professional Teeth Whitening Toothp...   \n","...          ...                                                ...   \n","4525  B01HBS87ZS  COSMEDIX Simply Brilliant 24/7 Brightening Tre...   \n","4526  B01HBS7WW2  COSMEDIX Phytoharmony, Balancing Moisturizer, ...   \n","4527  B01HBS7XP8  COSMEDIX Benefit Balance Antioxidant Infused T...   \n","4528  B01HGSJPWM  ELEMIS Frangipani Monoi Hand Cream and Nail Cr...   \n","4529  B01HIIO7Q4  Klorane Conditioner with Pomegranate - Color-T...   \n","\n","                                            description    price  \\\n","0     ['After a long day of handling thorny situatio...  $30.00    \n","1     ['This liquid soap with convenient pump dispen...  $15.99    \n","2     [\"Remember why you love your favorite blanket?...  $18.00    \n","3     ['<P><STRONG>Please note: Due to product impro...  $21.73    \n","4     ['Created by Dr. Irwin Smigel, world-renowned ...  $23.00    \n","...                                                 ...      ...   \n","4525  ['Uncover remarkable results with 10 skin-spec...  $60.00    \n","4526  ['Formulated specifically for women with matur...  $60.00    \n","4527  ['Soothe, calm and nourish the skin with green...  $38.00    \n","4528  ['This luxurious hand and nail cream, enriched...  $31.87    \n","4529  ['With a color-enhancing complex, this conditi...  $20.00    \n","\n","                                  first_imageURLHighRes  \\\n","0     https://images-na.ssl-images-amazon.com/images...   \n","1     https://images-na.ssl-images-amazon.com/images...   \n","2     https://images-na.ssl-images-amazon.com/images...   \n","3     https://images-na.ssl-images-amazon.com/images...   \n","4     https://images-na.ssl-images-amazon.com/images...   \n","...                                                 ...   \n","4525  https://images-na.ssl-images-amazon.com/images...   \n","4526  https://images-na.ssl-images-amazon.com/images...   \n","4527  https://images-na.ssl-images-amazon.com/images...   \n","4528  https://images-na.ssl-images-amazon.com/images...   \n","4529  https://images-na.ssl-images-amazon.com/images...   \n","\n","                                                Summary  year  \\\n","0     Crabtree &amp; Evelyn - Gardener's Ultra-Moist...  2018   \n","1     Crabtree &amp; Evelyn Hand Soap, Gardeners, 10...  2018   \n","2     Soy Milk Hand Crme [\"Remember why you love you...  2018   \n","3     Supersmile Powdered Mouthrinse ['<P><STRONG>Pl...  2018   \n","4     Supersmile Professional Teeth Whitening Toothp...  2018   \n","...                                                 ...   ...   \n","4525  COSMEDIX Simply Brilliant 24/7 Brightening Tre...  2018   \n","4526  COSMEDIX Phytoharmony, Balancing Moisturizer, ...  2018   \n","4527  COSMEDIX Benefit Balance Antioxidant Infused T...  2018   \n","4528  ELEMIS Frangipani Monoi Hand Cream and Nail Cr...  2018   \n","4529  Klorane Conditioner with Pomegranate - Color-T...  2018   \n","\n","                                             Category  \n","0     Hand Care: Creams, Lotions , Cleansers & Gloves  \n","1     Hand Care: Creams, Lotions , Cleansers & Gloves  \n","2     Hand Care: Creams, Lotions , Cleansers & Gloves  \n","3                 Oral Care: Mouthwashes & Toothpaste  \n","4                 Oral Care: Mouthwashes & Toothpaste  \n","...                                               ...  \n","4525                Face Care: Serums, Mists & Toners  \n","4526                Face Care: Moisturizers & Creams   \n","4527                Face Care: Serums, Mists & Toners  \n","4528                   Nail Care: Oils, Creams & Gels  \n","4529                          Hair Care: Conditioners  \n","\n","[4530 rows x 8 columns]>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from prettytable import PrettyTable\n","\n","# Assuming 'df' is your DataFrame\n","\n","# Selecting the first 5 rows and relevant columns\n","subset_df = df[['asin', 'description']].head(1)\n","\n","# Creating a PrettyTable object\n","table = PrettyTable()\n","\n","# Adding columns to the table\n","table.field_names = [\"ASIN\", \"Raw Description\"]\n","\n","# Setting up word wrapping for the 'Summary' column\n","table.align['description'] = 'l'\n","\n","# Populating the table with data\n","for _, row in subset_df.iterrows():\n","    # Wrapping the 'Summary' text\n","    wrapped_summary = \"\\n\".join([row['description'][i:i + 200] for i in range(0, len(row['description']), 200)])\n","    table.add_row([row['asin'], wrapped_summary])\n","\n","# Printing the table\n","print(table)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6SlHyOuAOAi","executionInfo":{"status":"ok","timestamp":1702266545276,"user_tz":480,"elapsed":182,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"366a8df0-c7b9-43fc-fb72-e3456b40e5d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|    ASIN    |                                                                                             Raw Description                                                                                              |\n","+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| B00004U9V2 | ['After a long day of handling thorny situations, our new hand therapy pump is just the help you need. It contains shea butter as well as extracts of yarrow, clover and calendula to help soothe and co |\n","|            | ndition work-roughened hands.', 'By Crabtree & Evelyn', 'The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straig |\n","|            | ht from the garden.', 'We&#039;ve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to he |\n","|            | lp replenish lost moisture. Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while th |\n","|            | e hydrating power of Vitamin E, Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this garden-inspired treatment. Skin is left silky-soft and delicately scent |\n","|            | ed.', 'How to use:', 'Dab a pea-sized amount to palms and work over skin and nails. Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herb-infused steps.', 'Originally created |\n","|            |  to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refre |\n","|            | shing sage extract.', 'We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from |\n","|            |  which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to thi |\n","|            |                                                                                                 s day.']                                                                                                 |\n","+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"SesiP_geCSue"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explore the List of Categories"],"metadata":{"id":"hXcgLwa6wu2c"}},{"cell_type":"code","source":["# Display categories and counts in alphabetical order\n","category_counts = df['Category'].value_counts()\n","category_counts_sorted = category_counts.sort_index()\n","\n","print(\"Categories and Counts Sorted by First Letter:\")\n","for letter in sorted(set(category[0] for category in category_counts_sorted.index)):\n","    categories_starting_with_letter = category_counts_sorted[category_counts_sorted.index.str.startswith(letter)]\n","    print(f\"\\nStarting with letter '{letter}':\")\n","    print(categories_starting_with_letter)\n","\n","# Display total count of all categories\n","total_count = category_counts_sorted.sum()\n","print(f\"\\nTotal Count of All Categories: {total_count}\")\n","\n","# Display the number of unique categories\n","unique_category_count = len(category_counts_sorted)\n","print(f\"\\nNumber of Unique Categories: {unique_category_count}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVyZVqP_k1ON","outputId":"28475a3e-3a27-4bc5-cf98-ba0ee4b8f4eb","executionInfo":{"status":"ok","timestamp":1702266557330,"user_tz":480,"elapsed":211,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Categories and Counts Sorted by First Letter:\n","\n","Starting with letter 'B':\n","Baby Care: Cleansers, Creams & Lotions         29\n","Beard & Mustache Care: Oils, Serums & Gels     17\n","Body Care: Butters & Oils                      25\n","Body Care: Cleansers                           96\n","Body Care: Exfoliants & Scrubs                 19\n","Body Care: Lotions & Mists                    162\n","Body Care: Mini Kits                           10\n","Body Care: Neck Creams & Ointments             14\n","Body Care: Tools & Accessories                 36\n","Name: Category, dtype: int64\n","\n","Starting with letter 'E':\n","Eye Care: Brow Gels, Serums & Pencils      23\n","Eye Care: Brow Gels, Serums & Pencils      12\n","Eye Care: Eye Shadows                      47\n","Eye Care: Eyeliners                        49\n","Eye Care: Mascara                          37\n","Eye Care: Serums & Creams                 107\n","Eye Care: Tools & Accessories              12\n","Name: Category, dtype: int64\n","\n","Starting with letter 'F':\n","Face Care: Cleansers                  145\n","Face Care: Masks & Peels              109\n","Face Care: Moisturizers & Creams      270\n","Face Care: Scrubs                      29\n","Face Care: Serums, Mists & Toners     292\n","Face Care: SkinCare/Makeup Kits        33\n","Foot Care: Foot Creams and Lotions     16\n","Name: Category, dtype: int64\n","\n","Starting with letter 'H':\n","Hair Care: Accessories                              14\n","Hair Care: Brushes                                  24\n","Hair Care: Conditioners                            276\n","Hair Care: Gels & Pomades                          195\n","Hair Care: Hair Dye                                 18\n","Hair Care: Masks                                    97\n","Hair Care: Oils & Serums                            75\n","Hair Care: Shampoo & Conditioner Kits               28\n","Hair Care: Shampoos                                309\n","Hair Care: Spray & Mousse                          256\n","Hair Care: Styling Tools                           190\n","Hand Care: Creams, Lotions , Cleansers & Gloves     73\n","Name: Category, dtype: int64\n","\n","Starting with letter 'L':\n","Lip Care: Lip Gloss           15\n","Lip Care: Lip Liners           8\n","Lip Care: Serums & Balms      52\n","Lip Care: Sticks & Crayons    53\n","Name: Category, dtype: int64\n","\n","Starting with letter 'M':\n","Makeup: Blush, Highlighters & Shimmers    50\n","Makeup: Color Correctors & Concealers     35\n","Makeup: Foundations & CC Creams           69\n","Makeup: Powders & Bronzers                66\n","Makeup: Primers                           29\n","Makeup: Remover Oils & Balms              55\n","Makeup: Tools & Accessories               25\n","Name: Category, dtype: int64\n","\n","Starting with letter 'N':\n","Nail Care: Base Coat               10\n","Nail Care: Color Polishes         125\n","Nail Care: Oils, Creams & Gels     35\n","Nail Care: Tools & Accessories      9\n","Nail Care: Top Coat                15\n","Name: Category, dtype: int64\n","\n","Starting with letter 'O':\n","Oral Care: Mouthwashes & Toothpaste    15\n","Oral Care: Tools & Accessories         17\n","Name: Category, dtype: int64\n","\n","Starting with letter 'P':\n","Personal Care: Home Fragrances                     30\n","Personal Care: Perfumes & Deodrants               363\n","Personal Care: Shaving Creams, Lotions & Gels      95\n","Personal Care: Shaving Tools & Accessories         30\n","Personal Care: Water Bottles                        9\n","Preganancy Care: Cleansers, Creams & Lotions        8\n","Name: Category, dtype: int64\n","\n","Starting with letter 'S':\n","Skin Care: Sunscreens                157\n","Skin Care: Supplements & Oinments     11\n","Name: Category, dtype: int64\n","\n","Total Count of All Categories: 4530\n","\n","Number of Unique Categories: 61\n"]}]},{"cell_type":"markdown","source":["### Implement the NLP Tasks"],"metadata":{"id":"r0vEkyrPw0jB"}},{"cell_type":"markdown","source":["## 1. NLP Task: Text Cleaning"],"metadata":{"id":"aITIUBWsw4vU"}},{"cell_type":"code","source":["# Remove duplicates\n","df.drop_duplicates(inplace=True)\n","\n","# Remove rows with missing values in relevant columns\n","df.dropna(subset=['Summary', 'Category'], inplace=True)\n","\n","# Remove any special characters from the 'summary' column\n","df['summary_cleaned'] = df['Summary'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n","df['description_cleaned'] = df['description'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n","# Print the count of features\n","print(\"Count of Features After Data Cleaning:\")\n","print(df.shape)\n","column_counts = df.count()\n","print(\"\\nCounts of Each Column:\")\n","print(column_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23rroF0ooY84","outputId":"e89d6a0b-3239-483d-874e-8d3ee42f8bd7","executionInfo":{"status":"ok","timestamp":1702266861665,"user_tz":480,"elapsed":721,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Count of Features After Data Cleaning:\n","(4530, 10)\n","\n","Counts of Each Column:\n","asin                     4530\n","title                    4530\n","description              4530\n","price                    4530\n","first_imageURLHighRes    4530\n","Summary                  4530\n","year                     4530\n","Category                 4530\n","summary_cleaned          4530\n","description_cleaned      4530\n","dtype: int64\n"]}]},{"cell_type":"code","source":["from prettytable import PrettyTable\n","\n","# Assuming 'df' is your DataFrame\n","\n","# Selecting the first 5 rows and relevant columns\n","subset_df = df[['asin', 'description_cleaned']].head(1)\n","\n","# Creating a PrettyTable object\n","table = PrettyTable()\n","\n","# Adding columns to the table\n","table.field_names = [\"ASIN\", \"Cleaned Product Description\"]\n","\n","# Setting up word wrapping for the 'Summary' column\n","table.align['description_cleaned'] = 'l'\n","\n","# Populating the table with data\n","for _, row in subset_df.iterrows():\n","    # Wrapping the 'Summary' text\n","    wrapped_summary = \"\\n\".join([row['description_cleaned'][i:i + 200] for i in range(0, len(row['description_cleaned']), 200)])\n","    table.add_row([row['asin'], wrapped_summary])\n","\n","# Printing the table\n","print(table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZP3UefdCium","executionInfo":{"status":"ok","timestamp":1702266571702,"user_tz":480,"elapsed":166,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"ff7f850c-81ad-4368-a402-2d18b8c83d90"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|    ASIN    |                                                                                       Cleaned Product Description                                                                                        |\n","+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| B00004U9V2 | After a long day of handling thorny situations our new hand therapy pump is just the help you need It contains shea butter as well as extracts of yarrow clover and calendula to help soothe and conditi |\n","|            | on workroughened hands By Crabtree  Evelyn The aromatic benefits of herbs are varied and farreaching so we combined a whole bunch of them into one restoratively fragrant lineup straight from the garde |\n","|            | n Weve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to help replenish lost moisture  |\n","|            | Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while the hydrating power of Vitamin |\n","|            |  E Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this gardeninspired treatment Skin is left silkysoft and delicately scented How to use Dab a peasized amo |\n","|            | unt to palms and work over skin and nails Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herbinfused steps Originally created to appeal to a horticulturists wealth of knowl |\n","|            | edge about the healing power of herbs this botanical range is formulated with cleansing cucumber extract purifying rosemary extract oak moss and refreshing sage extract We search the world for natural |\n","|            |  ingredients and fragrance journeys that enable our customers to live a life cultivated Inspired by the Crabapple Tree the original species from which all cultivated apple trees have derived and John  |\n","|            |                             Evelyn the th century renaissance Englishman whose motto Explore Everything Keep The Best has provided inspiration from our founding to this day                             |\n","+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## 2. NLP Task: Implementing Tokenization, Stop Words Removal and Lemmatization\n"],"metadata":{"id":"iFJJ-_FOxAwo"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download the nltk data (if not already downloaded)\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Lemmatization function\n","def lemmatize_text(tokens):\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","    return lemmatized_tokens\n","\n","# Tokenization function\n","def tokenize_text(text):\n","    # Tokenize the text\n","    tokens = word_tokenize(text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n","\n","    return tokens\n","\n","# Apply tokenization to the 'Summary' column\n","df['summary_tokens'] = df['summary_cleaned'].apply(tokenize_text)\n","\n","# Apply lemmatization to the tokenized column\n","df['summary_lemmatized'] = df['summary_tokens'].apply(lemmatize_text)\n","\n","# Display the DataFrame with the tokenized and lemmatized columns\n","print(df[['summary_cleaned', 'summary_tokens', 'summary_lemmatized']])\n","\n","\n","print(df.columns)\n","\n","\n","\n","df.to_csv(\"Cleaned_Products_Data.csv\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJcdnlGKqJXP","outputId":"5313e9f2-517e-4a72-e10f-d213f903f424","executionInfo":{"status":"ok","timestamp":1702266871220,"user_tz":480,"elapsed":5707,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["                                        summary_cleaned  \\\n","0     Crabtree amp Evelyn  Gardeners UltraMoisturisi...   \n","1     Crabtree amp Evelyn Hand Soap Gardeners  fl oz...   \n","2     Soy Milk Hand Crme Remember why you love your ...   \n","3     Supersmile Powdered Mouthrinse PSTRONGPlease n...   \n","4     Supersmile Professional Teeth Whitening Toothp...   \n","...                                                 ...   \n","4525  COSMEDIX Simply Brilliant  Brightening Treatme...   \n","4526  COSMEDIX Phytoharmony Balancing Moisturizer  O...   \n","4527  COSMEDIX Benefit Balance Antioxidant Infused T...   \n","4528  ELEMIS Frangipani Monoi Hand Cream and Nail Cr...   \n","4529  Klorane Conditioner with Pomegranate  ColorTre...   \n","\n","                                         summary_tokens  \\\n","0     [crabtree, amp, evelyn, gardeners, ultramoistu...   \n","1     [crabtree, amp, evelyn, hand, soap, gardeners,...   \n","2     [soy, milk, hand, crme, remember, love, favori...   \n","3     [supersmile, powdered, mouthrinse, pstrongplea...   \n","4     [supersmile, professional, teeth, whitening, t...   \n","...                                                 ...   \n","4525  [cosmedix, simply, brilliant, brightening, tre...   \n","4526  [cosmedix, phytoharmony, balancing, moisturize...   \n","4527  [cosmedix, benefit, balance, antioxidant, infu...   \n","4528  [elemis, frangipani, monoi, hand, cream, nail,...   \n","4529  [klorane, conditioner, pomegranate, colortreat...   \n","\n","                                     summary_lemmatized  \n","0     [crabtree, amp, evelyn, gardener, ultramoistur...  \n","1     [crabtree, amp, evelyn, hand, soap, gardener, ...  \n","2     [soy, milk, hand, crme, remember, love, favori...  \n","3     [supersmile, powdered, mouthrinse, pstrongplea...  \n","4     [supersmile, professional, teeth, whitening, t...  \n","...                                                 ...  \n","4525  [cosmedix, simply, brilliant, brightening, tre...  \n","4526  [cosmedix, phytoharmony, balancing, moisturize...  \n","4527  [cosmedix, benefit, balance, antioxidant, infu...  \n","4528  [elemi, frangipani, monoi, hand, cream, nail, ...  \n","4529  [klorane, conditioner, pomegranate, colortreat...  \n","\n","[4530 rows x 3 columns]\n","Index(['asin', 'title', 'description', 'price', 'first_imageURLHighRes',\n","       'Summary', 'year', 'Category', 'summary_cleaned', 'description_cleaned',\n","       'summary_tokens', 'summary_lemmatized'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["from prettytable import PrettyTable\n","from textwrap import wrap\n","\n","# Assuming 'df' is your DataFrame\n","selected_asin = 'B00004U9V2'  # Replace with the specific ASIN you want to analyze\n","\n","# Create a PrettyTable object\n","nlp_table = PrettyTable()\n","\n","# Adding columns to the table\n","nlp_table.field_names = [\"NLP Technique\", \"Before NLP\"]\n","\n","# Select the row for the specific ASIN\n","selected_row = df[df['asin'] == selected_asin].iloc[0]\n","\n","# Tokenization\n","before_tokenization = selected_row['summary_tokens']\n","\n","# Lemmatization\n","before_lemmatization = selected_row['summary_lemmatized']\n","\n","# Function to wrap text\n","def wrap_text(text, width=30):\n","    if isinstance(text, list):\n","        text = ' '.join(text)\n","    return \"\\n\".join(wrap(text, width=width))\n","\n","# Populate the table with wrapped text\n","nlp_table.add_row([\"Tokenization\", wrap_text(before_tokenization)])\n","nlp_table.add_row([\"Lemmatization\", wrap_text(before_lemmatization)])\n","\n","# Print the table\n","print(f\"Before NLP for ASIN '{selected_asin}':\\n{nlp_table}\")\n","\n","print(f\"Before NLP for ASIN '{selected_asin}':\\n{nlp_table}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28EOrGr4Dax_","executionInfo":{"status":"ok","timestamp":1702266657908,"user_tz":480,"elapsed":148,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"bd03097d-c78f-459f-b244-a9f6fa385394"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Before NLP for ASIN 'B00004U9V2':\n","+---------------+--------------------------------+\n","| NLP Technique |           Before NLP           |\n","+---------------+--------------------------------+\n","|  Tokenization | crabtree amp evelyn gardeners  |\n","|               | ultramoisturising hand therapy |\n","|               |  pump g oz long day handling   |\n","|               |   thorny situations new hand   |\n","|               |     therapy pump help need     |\n","|               |   contains shea butter well    |\n","|               |     extracts yarrow clover     |\n","|               |     calendula help soothe      |\n","|               | condition workroughened hands  |\n","|               |    crabtree evelyn aromatic    |\n","|               |     benefits herbs varied      |\n","|               |   farreaching combined whole   |\n","|               |    bunch one restoratively     |\n","|               |    fragrant lineup straight    |\n","|               |     garden weve formulated     |\n","|               |  gardeners hand therapy myrrh  |\n","|               |  extract help condition nails  |\n","|               |    cuticles well skin super    |\n","|               |  hydrators macadamia seed oil  |\n","|               |   shea butter help replenish   |\n","|               |   lost moisture rich herbal    |\n","|               | extracts like cooling cucumber |\n","|               |    rosemary leaf favourite     |\n","|               |   antioxidants help protect    |\n","|               |       hands daily urban        |\n","|               |     environmental stresses     |\n","|               |   hydrating power vitamin e    |\n","|               |   hyaluronic acid ceramides    |\n","|               |    contribute improve skins    |\n","|               |    natural moisture barrier    |\n","|               | gardeninspired treatment skin  |\n","|               |   left silkysoft delicately    |\n","|               |    scented use dab peasized    |\n","|               |  amount palms work skin nails  |\n","|               |  combine gardeners hand wash   |\n","|               |   hand scrub get silky skin    |\n","|               |    three herbinfused steps     |\n","|               |   originally created appeal    |\n","|               |     horticulturists wealth     |\n","|               | knowledge healing power herbs  |\n","|               |   botanical range formulated   |\n","|               |   cleansing cucumber extract   |\n","|               | purifying rosemary extract oak |\n","|               |  moss refreshing sage extract  |\n","|               |      search world natural      |\n","|               | ingredients fragrance journeys |\n","|               |   enable customers live life   |\n","|               | cultivated inspired crabapple  |\n","|               |     tree original species      |\n","|               | cultivated apple trees derived |\n","|               |     john evelyn th century     |\n","|               |  renaissance englishman whose  |\n","|               | motto explore everything keep  |\n","|               |   best provided inspiration    |\n","|               |          founding day          |\n","| Lemmatization |  crabtree amp evelyn gardener  |\n","|               | ultramoisturising hand therapy |\n","|               |  pump g oz long day handling   |\n","|               |   thorny situation new hand    |\n","|               |     therapy pump help need     |\n","|               |   contains shea butter well    |\n","|               |     extract yarrow clover      |\n","|               |     calendula help soothe      |\n","|               |  condition workroughened hand  |\n","|               |    crabtree evelyn aromatic    |\n","|               |      benefit herb varied       |\n","|               |   farreaching combined whole   |\n","|               |    bunch one restoratively     |\n","|               |    fragrant lineup straight    |\n","|               |     garden weve formulated     |\n","|               |  gardener hand therapy myrrh   |\n","|               |  extract help condition nail   |\n","|               |    cuticle well skin super     |\n","|               |  hydrators macadamia seed oil  |\n","|               |   shea butter help replenish   |\n","|               |   lost moisture rich herbal    |\n","|               | extract like cooling cucumber  |\n","|               |    rosemary leaf favourite     |\n","|               | antioxidant help protect hand  |\n","|               |   daily urban environmental    |\n","|               | stress hydrating power vitamin |\n","|               |  e hyaluronic acid ceramides   |\n","|               |    contribute improve skin     |\n","|               |    natural moisture barrier    |\n","|               | gardeninspired treatment skin  |\n","|               |   left silkysoft delicately    |\n","|               |    scented use dab peasized    |\n","|               |   amount palm work skin nail   |\n","|               |   combine gardener hand wash   |\n","|               |   hand scrub get silky skin    |\n","|               |     three herbinfused step     |\n","|               |   originally created appeal    |\n","|               |     horticulturist wealth      |\n","|               |  knowledge healing power herb  |\n","|               |   botanical range formulated   |\n","|               |   cleansing cucumber extract   |\n","|               | purifying rosemary extract oak |\n","|               |  moss refreshing sage extract  |\n","|               |      search world natural      |\n","|               |  ingredient fragrance journey  |\n","|               |   enable customer live life    |\n","|               | cultivated inspired crabapple  |\n","|               |      tree original specie      |\n","|               | cultivated apple tree derived  |\n","|               |     john evelyn th century     |\n","|               |  renaissance englishman whose  |\n","|               | motto explore everything keep  |\n","|               |   best provided inspiration    |\n","|               |          founding day          |\n","+---------------+--------------------------------+\n","Before NLP for ASIN 'B00004U9V2':\n","+---------------+--------------------------------+\n","| NLP Technique |           Before NLP           |\n","+---------------+--------------------------------+\n","|  Tokenization | crabtree amp evelyn gardeners  |\n","|               | ultramoisturising hand therapy |\n","|               |  pump g oz long day handling   |\n","|               |   thorny situations new hand   |\n","|               |     therapy pump help need     |\n","|               |   contains shea butter well    |\n","|               |     extracts yarrow clover     |\n","|               |     calendula help soothe      |\n","|               | condition workroughened hands  |\n","|               |    crabtree evelyn aromatic    |\n","|               |     benefits herbs varied      |\n","|               |   farreaching combined whole   |\n","|               |    bunch one restoratively     |\n","|               |    fragrant lineup straight    |\n","|               |     garden weve formulated     |\n","|               |  gardeners hand therapy myrrh  |\n","|               |  extract help condition nails  |\n","|               |    cuticles well skin super    |\n","|               |  hydrators macadamia seed oil  |\n","|               |   shea butter help replenish   |\n","|               |   lost moisture rich herbal    |\n","|               | extracts like cooling cucumber |\n","|               |    rosemary leaf favourite     |\n","|               |   antioxidants help protect    |\n","|               |       hands daily urban        |\n","|               |     environmental stresses     |\n","|               |   hydrating power vitamin e    |\n","|               |   hyaluronic acid ceramides    |\n","|               |    contribute improve skins    |\n","|               |    natural moisture barrier    |\n","|               | gardeninspired treatment skin  |\n","|               |   left silkysoft delicately    |\n","|               |    scented use dab peasized    |\n","|               |  amount palms work skin nails  |\n","|               |  combine gardeners hand wash   |\n","|               |   hand scrub get silky skin    |\n","|               |    three herbinfused steps     |\n","|               |   originally created appeal    |\n","|               |     horticulturists wealth     |\n","|               | knowledge healing power herbs  |\n","|               |   botanical range formulated   |\n","|               |   cleansing cucumber extract   |\n","|               | purifying rosemary extract oak |\n","|               |  moss refreshing sage extract  |\n","|               |      search world natural      |\n","|               | ingredients fragrance journeys |\n","|               |   enable customers live life   |\n","|               | cultivated inspired crabapple  |\n","|               |     tree original species      |\n","|               | cultivated apple trees derived |\n","|               |     john evelyn th century     |\n","|               |  renaissance englishman whose  |\n","|               | motto explore everything keep  |\n","|               |   best provided inspiration    |\n","|               |          founding day          |\n","| Lemmatization |  crabtree amp evelyn gardener  |\n","|               | ultramoisturising hand therapy |\n","|               |  pump g oz long day handling   |\n","|               |   thorny situation new hand    |\n","|               |     therapy pump help need     |\n","|               |   contains shea butter well    |\n","|               |     extract yarrow clover      |\n","|               |     calendula help soothe      |\n","|               |  condition workroughened hand  |\n","|               |    crabtree evelyn aromatic    |\n","|               |      benefit herb varied       |\n","|               |   farreaching combined whole   |\n","|               |    bunch one restoratively     |\n","|               |    fragrant lineup straight    |\n","|               |     garden weve formulated     |\n","|               |  gardener hand therapy myrrh   |\n","|               |  extract help condition nail   |\n","|               |    cuticle well skin super     |\n","|               |  hydrators macadamia seed oil  |\n","|               |   shea butter help replenish   |\n","|               |   lost moisture rich herbal    |\n","|               | extract like cooling cucumber  |\n","|               |    rosemary leaf favourite     |\n","|               | antioxidant help protect hand  |\n","|               |   daily urban environmental    |\n","|               | stress hydrating power vitamin |\n","|               |  e hyaluronic acid ceramides   |\n","|               |    contribute improve skin     |\n","|               |    natural moisture barrier    |\n","|               | gardeninspired treatment skin  |\n","|               |   left silkysoft delicately    |\n","|               |    scented use dab peasized    |\n","|               |   amount palm work skin nail   |\n","|               |   combine gardener hand wash   |\n","|               |   hand scrub get silky skin    |\n","|               |     three herbinfused step     |\n","|               |   originally created appeal    |\n","|               |     horticulturist wealth      |\n","|               |  knowledge healing power herb  |\n","|               |   botanical range formulated   |\n","|               |   cleansing cucumber extract   |\n","|               | purifying rosemary extract oak |\n","|               |  moss refreshing sage extract  |\n","|               |      search world natural      |\n","|               |  ingredient fragrance journey  |\n","|               |   enable customer live life    |\n","|               | cultivated inspired crabapple  |\n","|               |      tree original specie      |\n","|               | cultivated apple tree derived  |\n","|               |     john evelyn th century     |\n","|               |  renaissance englishman whose  |\n","|               | motto explore everything keep  |\n","|               |   best provided inspiration    |\n","|               |          founding day          |\n","+---------------+--------------------------------+\n"]}]},{"cell_type":"code","source":["from prettytable import PrettyTable\n","from textwrap import wrap\n","\n","# Assuming 'df' is your DataFrame\n","selected_asin = 'B00004U9V2'  # Replace with the specific ASIN you want to analyze\n","\n","# Create a PrettyTable object\n","nlp_table = PrettyTable()\n","\n","# Adding columns to the table\n","nlp_table.field_names = [\"NLP Technique\", \"Transformed Product Description\"]\n","\n","# Select the row for the specific ASIN\n","selected_row = df[df['asin'] == selected_asin].iloc[0]\n","\n","# Tokenization\n","summary_tokens = selected_row['summary_tokens']\n","wrapped_summary_tokens = \"\\n\".join(wrap(', '.join(summary_tokens), width=200))\n","nlp_table.add_row([\"Tokenization\", wrapped_summary_tokens])\n","\n","# Lemmatization\n","summary_lemmatized = selected_row['summary_lemmatized']\n","wrapped_summary_lemmatized = \"\\n\".join(wrap(', '.join(summary_lemmatized), width=200))\n","nlp_table.add_row([\"Lemmatization\", wrapped_summary_lemmatized])\n","\n","# Set column alignment to 'l' for left-aligned text\n","nlp_table.align[\"NLP Technique\"] = \"l\"\n","nlp_table.align[\"Output\"] = \"l\"\n","\n","# Print the table\n","print(f\"NLP Output for ASIN '{selected_asin}':\\n{nlp_table}\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8XAyk0RGk7u","executionInfo":{"status":"ok","timestamp":1702266661226,"user_tz":480,"elapsed":163,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"f746500c-afe3-486e-b25f-31d3f5c5f6ed"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["NLP Output for ASIN 'B00004U9V2':\n","+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| NLP Technique |                                                                                     Transformed Product Description                                                                                      |\n","+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Tokenization  | crabtree, amp, evelyn, gardeners, ultramoisturising, hand, therapy, pump, g, oz, long, day, handling, thorny, situations, new, hand, therapy, pump, help, need, contains, shea, butter, well, extracts,  |\n","|               |    yarrow, clover, calendula, help, soothe, condition, workroughened, hands, crabtree, evelyn, aromatic, benefits, herbs, varied, farreaching, combined, whole, bunch, one, restoratively, fragrant,     |\n","|               |     lineup, straight, garden, weve, formulated, gardeners, hand, therapy, myrrh, extract, help, condition, nails, cuticles, well, skin, super, hydrators, macadamia, seed, oil, shea, butter, help,      |\n","|               |   replenish, lost, moisture, rich, herbal, extracts, like, cooling, cucumber, rosemary, leaf, favourite, antioxidants, help, protect, hands, daily, urban, environmental, stresses, hydrating, power,    |\n","|               |   vitamin, e, hyaluronic, acid, ceramides, contribute, improve, skins, natural, moisture, barrier, gardeninspired, treatment, skin, left, silkysoft, delicately, scented, use, dab, peasized, amount,    |\n","|               |   palms, work, skin, nails, combine, gardeners, hand, wash, hand, scrub, get, silky, skin, three, herbinfused, steps, originally, created, appeal, horticulturists, wealth, knowledge, healing, power,   |\n","|               | herbs, botanical, range, formulated, cleansing, cucumber, extract, purifying, rosemary, extract, oak, moss, refreshing, sage, extract, search, world, natural, ingredients, fragrance, journeys, enable, |\n","|               |      customers, live, life, cultivated, inspired, crabapple, tree, original, species, cultivated, apple, trees, derived, john, evelyn, th, century, renaissance, englishman, whose, motto, explore,      |\n","|               |                                                                       everything, keep, best, provided, inspiration, founding, day                                                                       |\n","| Lemmatization |   crabtree, amp, evelyn, gardener, ultramoisturising, hand, therapy, pump, g, oz, long, day, handling, thorny, situation, new, hand, therapy, pump, help, need, contains, shea, butter, well, extract,   |\n","|               |  yarrow, clover, calendula, help, soothe, condition, workroughened, hand, crabtree, evelyn, aromatic, benefit, herb, varied, farreaching, combined, whole, bunch, one, restoratively, fragrant, lineup,  |\n","|               |  straight, garden, weve, formulated, gardener, hand, therapy, myrrh, extract, help, condition, nail, cuticle, well, skin, super, hydrators, macadamia, seed, oil, shea, butter, help, replenish, lost,   |\n","|               |  moisture, rich, herbal, extract, like, cooling, cucumber, rosemary, leaf, favourite, antioxidant, help, protect, hand, daily, urban, environmental, stress, hydrating, power, vitamin, e, hyaluronic,   |\n","|               |    acid, ceramides, contribute, improve, skin, natural, moisture, barrier, gardeninspired, treatment, skin, left, silkysoft, delicately, scented, use, dab, peasized, amount, palm, work, skin, nail,    |\n","|               |     combine, gardener, hand, wash, hand, scrub, get, silky, skin, three, herbinfused, step, originally, created, appeal, horticulturist, wealth, knowledge, healing, power, herb, botanical, range,      |\n","|               |   formulated, cleansing, cucumber, extract, purifying, rosemary, extract, oak, moss, refreshing, sage, extract, search, world, natural, ingredient, fragrance, journey, enable, customer, live, life,    |\n","|               | cultivated, inspired, crabapple, tree, original, specie, cultivated, apple, tree, derived, john, evelyn, th, century, renaissance, englishman, whose, motto, explore, everything, keep, best, provided,  |\n","|               |                                                                                        inspiration, founding, day                                                                                        |\n","+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mI_AJ_qbDZk9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. NLP Task: Implementing Text Vectorization"],"metadata":{"id":"3AGxqQUixJ1z"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","\n","# Apply lemmatization to the tokenized column\n","df['summary_lemmatized'] = df['summary_tokens'].apply(lemmatize_text)\n","\n","# Convert the lemmatized tokens back to text\n","df['summary_lemmatized_text'] = df['summary_lemmatized'].apply(' '.join)\n","\n","# Apply TF-IDF vectorization\n","tfidf_vectorizer = TfidfVectorizer()\n","X = tfidf_vectorizer.fit_transform(df['summary_lemmatized_text'])\n","\n","# Create a DataFrame from the TF-IDF matrix\n","tfidf_df = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n","\n","# Display the DataFrame with TF-IDF values\n","print(tfidf_df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qhlh6kfsMYG","outputId":"bda321e9-9149-4ca6-f0a6-4a7fffb9c5c2","executionInfo":{"status":"ok","timestamp":1702266879490,"user_tz":480,"elapsed":2475,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["      aaqua   ab  abaca  abba  abc  abcderm  abdomen  abdominal   ability  \\\n","0       0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","1       0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","2       0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","3       0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","4       0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.017476   \n","...     ...  ...    ...   ...  ...      ...      ...        ...       ...   \n","4525    0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","4526    0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","4527    0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","4528    0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","4529    0.0  0.0    0.0   0.0  0.0      0.0      0.0        0.0  0.000000   \n","\n","      ablative  ...  zoma  zone  zooey  zoya  zoyas   zp  zptoni  zuza  \\\n","0          0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","1          0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","2          0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","3          0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","4          0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","...        ...  ...   ...   ...    ...   ...    ...  ...     ...   ...   \n","4525       0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","4526       0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","4527       0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","4528       0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","4529       0.0  ...   0.0   0.0    0.0   0.0    0.0  0.0     0.0   0.0   \n","\n","      zwilling  zyme  \n","0          0.0   0.0  \n","1          0.0   0.0  \n","2          0.0   0.0  \n","3          0.0   0.0  \n","4          0.0   0.0  \n","...        ...   ...  \n","4525       0.0   0.0  \n","4526       0.0   0.0  \n","4527       0.0   0.0  \n","4528       0.0   0.0  \n","4529       0.0   0.0  \n","\n","[4530 rows x 22092 columns]\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","from prettytable import PrettyTable\n","\n","# Define the text\n","text = \"\"\"\n","After a long day of handling thorny situations our new hand therapy pump is\n","just the help you need It contains shea butter as well as extracts of yarrow clover\n","and calendula to help soothe and condition workroughened hands \"\"\"\n","# Create a DataFrame with the text\n","df = pd.DataFrame({'text': [text]})\n","\n","# Apply TF-IDF vectorization\n","tfidf_vectorizer = TfidfVectorizer()\n","X = tfidf_vectorizer.fit_transform(df['text'])\n","\n","# Create a DataFrame from the TF-IDF matrix\n","tfidf_df = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n","\n","# Create a PrettyTable object\n","table = PrettyTable()\n","\n","# Define the column names\n","table.field_names = [\"TF-IDF Vector\"]\n","\n","# Select the TF-IDF vector for the provided text\n","tfidf_vector = tfidf_df.iloc[0]\n","\n","# Convert the TF-IDF vector to a string for display\n","formatted_vector = \", \".join([f\"{word}: {value:.2f}\" for word, value in zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vector)])\n","\n","# Add the TF-IDF vector as a row in the table\n","table.add_row([formatted_vector])\n","\n","# Set the table width to allow wrapping\n","table.max_width = 80  # Adjust the width as needed\n","\n","# Print the table\n","print(table)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G51_x91WRfg9","executionInfo":{"status":"ok","timestamp":1702266882604,"user_tz":480,"elapsed":184,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"732c7aa8-89b2-4f26-9357-7f2ab570d7e3"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------+\n","|                                  TF-IDF Vector                                   |\n","+----------------------------------------------------------------------------------+\n","|  after: 0.15, and: 0.29, as: 0.29, butter: 0.15, calendula: 0.15, clover: 0.15,  |\n","|     condition: 0.15, contains: 0.15, day: 0.15, extracts: 0.15, hand: 0.15,      |\n","|  handling: 0.15, hands: 0.15, help: 0.29, is: 0.15, it: 0.15, just: 0.15, long:  |\n","|    0.15, need: 0.15, new: 0.15, of: 0.29, our: 0.15, pump: 0.15, shea: 0.15,     |\n","|   situations: 0.15, soothe: 0.15, the: 0.15, therapy: 0.15, thorny: 0.15, to:    |\n","|          0.15, well: 0.15, workroughened: 0.15, yarrow: 0.15, you: 0.15          |\n","+----------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"IrpaMlYdAMsB","executionInfo":{"status":"ok","timestamp":1702266731890,"user_tz":480,"elapsed":171,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"f34dadea-3d11-4e7f-b101-adfff23cec23"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text\n","0  \\nAfter a long day of handling thorny situatio..."],"text/html":["\n","  <div id=\"df-6a59d996-1c55-474b-a72a-5fcb2ca15210\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\\nAfter a long day of handling thorny situatio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a59d996-1c55-474b-a72a-5fcb2ca15210')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6a59d996-1c55-474b-a72a-5fcb2ca15210 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6a59d996-1c55-474b-a72a-5fcb2ca15210');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["### Train the Classification Model"],"metadata":{"id":"xh2cNUKNxa4W"}},{"cell_type":"markdown","source":["Model 1 Multinomial Naive Bayes"],"metadata":{"id":"h3prqUjBZvn1"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Calculate sample weights\n","sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","# Train the classifier with sample weights\n","clf_nb = MultinomialNB()\n","clf_nb.fit(X_train, y_train, sample_weight=sample_weights)\n","\n","# Evaluate the classifier\n","y_pred = clf_nb.predict(X_test)\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","roc_auc = roc_auc_score(y_test, clf_nb.predict_proba(X_test), multi_class='ovr')\n","confusion = confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-Score:\", f1)\n","print(\"ROC-AUC:\", roc_auc)\n","print(\"Confusion Matrix:\")\n","print(confusion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"K2llqZdeurg1","outputId":"de1aa29f-54bc-47f0-f105-9e5462251081","executionInfo":{"status":"error","timestamp":1702266678548,"user_tz":480,"elapsed":409,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":13,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Category'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-1287119d9c99>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Category'"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"8Jppap1DZ9xE"}},{"cell_type":"markdown","source":["### Save the Trained model and vectoizer for future use"],"metadata":{"id":"HLsfAbf0xgNc"}},{"cell_type":"code","source":["import joblib\n","\n","# Save the re-trained model\n","joblib.dump(clf_nb, 'balanced_naive_bayes_model.pkl')\n","\n","# Save the TF-IDF vectorizer if you've created a new one or made changes\n","joblib.dump(tfidf_vectorizer, 'balanced_tfidf_vectorizer.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_QafBvKu5qh","outputId":"5716a0fd-707c-4c6a-c9dd-c9f14f5bda82","executionInfo":{"status":"ok","timestamp":1701634107636,"user_tz":480,"elapsed":1603,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['balanced_tfidf_vectorizer.pkl']"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Test the Trained Naive Bayes Model\n"],"metadata":{"id":"XTblonC2wB8d"}},{"cell_type":"markdown","source":["Model 1: Multinomial Naive Bayes"],"metadata":{"id":"lATA5Ynq4DGA"}},{"cell_type":"code","source":["# Assuming vectorizer and classification model 'clf' are already fitted and trained\n","\n","# Take a sample query\n","query = \"Comb\"\n","\n","# Debugging\n","print(f\"Query before prediction: {query}\")\n","\n","# Transform the query using the same TF-IDF vectorizer used for training the model\n","query_tfidf = tfidf_vectorizer.transform([query])\n","\n","\n","print(f\"TF-IDF for query: {query_tfidf.toarray()}\")\n","\n","\n","# Predict the category of the query\n","predicted_category = clf_nb.predict(query_tfidf)\n","\n","print(f\"The query belongs to the category: {predicted_category[0]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnyLBV6uvizp","outputId":"0e2b36c8-f567-4cd3-87ed-3e4e92384a3a","executionInfo":{"status":"ok","timestamp":1701634109463,"user_tz":480,"elapsed":211,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Query before prediction: Comb\n","TF-IDF for query: [[0. 0. 0. ... 0. 0. 0.]]\n","The query belongs to the category: Hair Care: Brushes\n"]}]},{"cell_type":"markdown","source":["Model 2: SVM"],"metadata":{"id":"QSr7lqXC5RJv"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import expon\n","from sklearn.svm import SVC\n","\n","# Define the target variable\n","y = df['Category']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# SVM Classifier with Randomized Search\n","svm_clf = SVC(class_weight='balanced')\n","random_search = RandomizedSearchCV(svm_clf, {\n","    'C': expon(scale=10),\n","    'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001],\n","    'kernel': ['rbf', 'linear']\n","}, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train, y_train)\n","best_clf_svm = random_search.best_estimator_\n","y_pred_svm = best_clf_svm.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred_svm)\n","precision = precision_score(y_test, y_pred_svm, average='weighted')\n","recall = recall_score(y_test, y_pred_svm, average='weighted')\n","f1 = f1_score(y_test, y_pred_svm, average='weighted')\n","# Calculate ROC-AUC using predict_proba\n","\n","confusion = confusion_matrix(y_test, y_pred_svm)\n","\n","print(\"Accuracy (SVM Randomized):\", accuracy)\n","print(\"Precision (SVM Randomized):\", precision)\n","print(\"Recall (SVM Randomized):\", recall)\n","print(\"F1-Score (SVM Randomized):\", f1)\n","\n","print(\"Confusion Matrix (SVM Randomized):\")\n","print(confusion)\n"],"metadata":{"id":"zSjgvnPF5QV4","executionInfo":{"status":"error","timestamp":1701721836931,"user_tz":480,"elapsed":306224,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"colab":{"base_uri":"https://localhost:8080/","height":480},"outputId":"201cc2e0-2de3-4fbf-d768-44678c065f0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-73a39a4ae513>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Calculate ROC-AUC using predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_clf_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    830\u001b[0m                 \u001b[0;34m\"predict_proba is not available when  probability=False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             )\n","\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"]}]},{"cell_type":"code","source":["pip install tabulate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUOCIsIyrkH3","executionInfo":{"status":"ok","timestamp":1702261322481,"user_tz":480,"elapsed":8872,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"58201d46-5086-48f0-a04a-c3a695995621"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import expon\n","from sklearn.svm import SVC\n","\n","# Define the target variable\n","y = df['Category']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# SVM Classifier with Randomized Search\n","svm_clf = SVC(class_weight='balanced')\n","random_search = RandomizedSearchCV(svm_clf, {\n","    'C': expon(scale=10),\n","    'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001],\n","    'kernel': ['rbf', 'linear']\n","}, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train, y_train)\n","best_clf_svm = random_search.best_estimator_\n","y_pred_svm = best_clf_svm.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred_svm)\n","precision = precision_score(y_test, y_pred_svm, average='weighted')\n","recall = recall_score(y_test, y_pred_svm, average='weighted')\n","f1 = f1_score(y_test, y_pred_svm, average='weighted')\n","# Calculate ROC-AUC using predict_proba\n","\n","confusion = confusion_matrix(y_test, y_pred_svm)\n","print(\"Accuracy (SVM Randomized):\", accuracy)\n","print(\"Precision (SVM Randomized):\", precision)\n","print(\"Recall (SVM Randomized):\", recall)\n","print(\"F1-Score (SVM Randomized):\", f1)\n","\n","# Print Confusion Matrix\n","print(\"Confusion Matrix (SVM Randomized):\")\n","print(confusion)\n","\n","# Generate and print the Classification Report\n","class_report = classification_report(y_test, y_pred_svm, target_names=df['Category'].unique(), output_dict=True)\n","class_report_df = pd.DataFrame(class_report).transpose()\n","\n","print(\"\\nClassification Report (SVM Randomized):\\n\")\n","print(tabulate(class_report_df, headers='keys', tablefmt='pretty'))"],"metadata":{"id":"29-wpJfZrcoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# ... (previous code remains the same)\n","\n","# Assuming 'best_clf_svm.pkl' is the file where you saved the model using joblib\n","best_clf_svm = joblib.load('best_clf_svm.pkl')\n","\n","# Predict using the loaded model\n","y_pred_svm = best_clf_svm.predict(X_test)\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred_svm)\n","precision = precision_score(y_test, y_pred_svm, average='weighted')\n","recall = recall_score(y_test, y_pred_svm, average='weighted')\n","f1 = f1_score(y_test, y_pred_svm, average='weighted')\n","confusion = confusion_matrix(y_test, y_pred_svm)\n","\n","# Print the results\n","print(\"Accuracy (SVM Randomized):\", accuracy)\n","print(\"Precision (SVM Randomized):\", precision)\n","print(\"Recall (SVM Randomized):\", recall)\n","print(\"F1-Score (SVM Randomized):\", f1)\n","\n","print(\"Confusion Matrix (SVM Randomized):\")\n","print(confusion)\n","\n","# Generate and print the classification report\n","class_report = classification_report(y_test, y_pred_svm)\n","print(\"Classification Report (SVM Randomized):\")\n","print(class_report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Biv-vawGnBRn","executionInfo":{"status":"ok","timestamp":1702261471449,"user_tz":480,"elapsed":2645,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"0f2bcd10-9b45-46a9-9dd1-53eacf9dfd72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (SVM Randomized): 0.9293598233995585\n","Precision (SVM Randomized): 0.9352445301117922\n","Recall (SVM Randomized): 0.9293598233995585\n","F1-Score (SVM Randomized): 0.929772172546837\n","Confusion Matrix (SVM Randomized):\n","[[ 6  0  0 ...  0  0  0]\n"," [ 0  3  0 ...  0  0  0]\n"," [ 0  0  6 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ...  1  0  0]\n"," [ 0  0  0 ...  0 30  0]\n"," [ 0  0  0 ...  0  0  2]]\n","Classification Report (SVM Randomized):\n","                                                 precision    recall  f1-score   support\n","\n","         Baby Care: Cleansers, Creams & Lotions       0.86      1.00      0.92         6\n","     Beard & Mustache Care: Oils, Serums & Gels       1.00      1.00      1.00         3\n","                      Body Care: Butters & Oils       0.86      0.75      0.80         8\n","                           Body Care: Cleansers       1.00      0.90      0.95        20\n","                 Body Care: Exfoliants & Scrubs       1.00      1.00      1.00         3\n","                     Body Care: Lotions & Mists       0.90      0.78      0.84        23\n","                           Body Care: Mini Kits       0.50      1.00      0.67         1\n","             Body Care: Neck Creams & Ointments       1.00      1.00      1.00         3\n","                 Body Care: Tools & Accessories       1.00      0.83      0.91         6\n","          Eye Care: Brow Gels, Serums & Pencils       1.00      1.00      1.00         3\n","         Eye Care: Brow Gels, Serums & Pencils        1.00      1.00      1.00         5\n","                          Eye Care: Eye Shadows       1.00      0.89      0.94         9\n","                            Eye Care: Eyeliners       1.00      0.83      0.91         6\n","                              Eye Care: Mascara       1.00      1.00      1.00         3\n","                      Eye Care: Serums & Creams       0.95      1.00      0.98        20\n","                  Eye Care: Tools & Accessories       1.00      0.80      0.89         5\n","                           Face Care: Cleansers       0.96      0.96      0.96        24\n","                       Face Care: Masks & Peels       0.95      0.95      0.95        21\n","              Face Care: Moisturizers & Creams        0.86      0.97      0.91        63\n","                              Face Care: Scrubs       1.00      1.00      1.00         4\n","              Face Care: Serums, Mists & Toners       0.89      0.92      0.90        60\n","                Face Care: SkinCare/Makeup Kits       1.00      0.86      0.92         7\n","             Foot Care: Foot Creams and Lotions       0.50      1.00      0.67         1\n","                         Hair Care: Accessories       1.00      1.00      1.00         5\n","                             Hair Care: Brushes       0.60      0.75      0.67         4\n","                        Hair Care: Conditioners       0.88      0.96      0.92        51\n","                      Hair Care: Gels & Pomades       0.97      0.92      0.95        39\n","                            Hair Care: Hair Dye       1.00      1.00      1.00         3\n","                               Hair Care: Masks       1.00      0.88      0.93        24\n","                       Hair Care: Oils & Serums       0.94      0.88      0.91        17\n","          Hair Care: Shampoo & Conditioner Kits       1.00      1.00      1.00         6\n","                            Hair Care: Shampoos       1.00      0.91      0.95        58\n","                      Hair Care: Spray & Mousse       0.85      0.98      0.91        41\n","                       Hair Care: Styling Tools       0.97      0.92      0.94        36\n","Hand Care: Creams, Lotions , Cleansers & Gloves       0.89      0.94      0.91        17\n","                            Lip Care: Lip Gloss       1.00      1.00      1.00         4\n","                           Lip Care: Lip Liners       1.00      1.00      1.00         1\n","                       Lip Care: Serums & Balms       0.88      0.88      0.88         8\n","                     Lip Care: Sticks & Crayons       1.00      0.78      0.88         9\n","         Makeup: Blush, Highlighters & Shimmers       0.91      0.83      0.87        12\n","          Makeup: Color Correctors & Concealers       1.00      1.00      1.00         7\n","                Makeup: Foundations & CC Creams       0.81      0.93      0.87        14\n","                     Makeup: Powders & Bronzers       0.77      0.91      0.83        11\n","                                Makeup: Primers       1.00      0.80      0.89         5\n","                   Makeup: Remover Oils & Balms       0.86      0.86      0.86         7\n","                    Makeup: Tools & Accessories       0.80      0.67      0.73         6\n","                           Nail Care: Base Coat       1.00      0.50      0.67         2\n","                     Nail Care: Color Polishes        1.00      0.94      0.97        33\n","                 Nail Care: Oils, Creams & Gels       0.82      1.00      0.90         9\n","                 Nail Care: Tools & Accessories       1.00      1.00      1.00         2\n","                            Nail Care: Top Coat       0.60      0.75      0.67         4\n","            Oral Care: Mouthwashes & Toothpaste       1.00      1.00      1.00         4\n","                 Oral Care: Tools & Accessories       1.00      1.00      1.00         4\n","                 Personal Care: Home Fragrances       1.00      1.00      1.00         9\n","            Personal Care: Perfumes & Deodrants       1.00      0.99      0.99        85\n"," Personal Care: Shaving Creams, Lotions & Gels        0.95      0.95      0.95        19\n","     Personal Care: Shaving Tools & Accessories       0.90      1.00      0.95         9\n","                   Personal Care: Water Bottles       1.00      1.00      1.00         1\n","   Preganancy Care: Cleansers, Creams & Lotions       1.00      0.50      0.67         2\n","                          Skin Care: Sunscreens       0.97      0.94      0.95        32\n","              Skin Care: Supplements & Oinments       1.00      1.00      1.00         2\n","\n","                                       accuracy                           0.93       906\n","                                      macro avg       0.93      0.91      0.91       906\n","                                   weighted avg       0.94      0.93      0.93       906\n","\n"]}]},{"cell_type":"code","source":["best_clf_svm = random_search.best_estimator_\n","y_pred_svm = best_clf_svm.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred_svm)\n","precision = precision_score(y_test, y_pred_svm, average='weighted')\n","recall = recall_score(y_test, y_pred_svm, average='weighted')\n","f1 = f1_score(y_test, y_pred_svm, average='weighted')\n","# Calculate ROC-AUC using predict_proba\n","\n","confusion = confusion_matrix(y_test, y_pred_svm)\n","\n","print(\"Accuracy (SVM Randomized):\", accuracy)\n","print(\"Precision (SVM Randomized):\", precision)\n","print(\"Recall (SVM Randomized):\", recall)\n","print(\"F1-Score (SVM Randomized):\", f1)\n","\n","print(\"Confusion Matrix (SVM Randomized):\")\n","print(confusion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9wfi0GcTkPHC","executionInfo":{"status":"ok","timestamp":1701722531495,"user_tz":480,"elapsed":2914,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"ca2f2658-63a6-4748-db6a-b3f57d502cb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (SVM Randomized): 0.7284768211920529\n","Precision (SVM Randomized): 0.7468374722067923\n","Recall (SVM Randomized): 0.7284768211920529\n","F1-Score (SVM Randomized): 0.7266401090950444\n","Confusion Matrix (SVM Randomized):\n","[[ 6  0  0 ...  0  0  0]\n"," [ 0  3  0 ...  0  0  0]\n"," [ 0  0  1 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0 22  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["Model 3: Multinomial Logistic Regression"],"metadata":{"id":"1L4Rcgld2w6e"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Calculate sample weights\n","sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","# Train the classifier with sample weights\n","clf_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n","clf_lr.fit(X_train, y_train, sample_weight=sample_weights)\n","\n","# Evaluate the classifier\n","y_pred = clf_lr.predict(X_test)\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","confusion = confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-Score:\", f1)\n","print(\"Confusion Matrix:\")\n","print(confusion)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"G6PrlQb62v-V","executionInfo":{"status":"error","timestamp":1702266910593,"user_tz":480,"elapsed":193,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"cb04d398-d9a7-4725-83d8-29b7b36eb9b4"},"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Category'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-b1ebba8d30ef>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Category'"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Calculate sample weights\n","sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","# Train the classifier with sample weights\n","clf_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n","clf_lr.fit(X_train, y_train, sample_weight=sample_weights)\n","\n","# Evaluate the classifier\n","y_prob_lr = clf_lr.predict_proba(X_test)\n","\n","# Choose the positive class probability (for multi-class problems)\n","# Assuming your target variable is encoded with integers starting from 0\n","positive_class_index = 1  # Change this according to your problem\n","\n","# Calculate ROC-AUC score\n","roc_auc = roc_auc_score(y_test == positive_class_index, y_prob_lr[:, positive_class_index], multi_class='ovr', average='weighted')\n","\n","# Calculate metrics\n","y_pred_lr = clf_lr.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred_lr)\n","precision = precision_score(y_test, y_pred_lr, average='weighted')\n","recall = recall_score(y_test, y_pred_lr, average='weighted')\n","f1 = f1_score(y_test, y_pred_lr, average='weighted')\n","confusion = confusion_matrix(y_test, y_pred_lr)\n","\n","print(\"Accuracy (Logistic Regression):\", accuracy)\n","print(\"Precision (Logistic Regression):\", precision)\n","print(\"Recall (Logistic Regression):\", recall)\n","print(\"F1-Score (Logistic Regression):\", f1)\n","print(\"ROC-AUC Score (Logistic Regression):\", roc_auc)\n","\n","print(\"Confusion Matrix (Logistic Regression):\")\n","print(confusion)\n"],"metadata":{"id":"lyFuv5CrpOQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XvQqIRT15kT6"}},{"cell_type":"code","source":["import joblib\n","\n","# Save the re-trained model\n","joblib.dump(clf_lr, 'multinomial_logistic_regression_model.pkl')\n","\n","# Save the TF-IDF vectorizer if you've created a new one or made changes\n","joblib.dump(tfidf_vectorizer, 'multinomial_logistic_regression_model.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXKICLET4UPD","executionInfo":{"status":"ok","timestamp":1701577365280,"user_tz":480,"elapsed":363,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"7d255c5f-1a47-4a24-c5e2-4823d0f6d20a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['multinomial_logistic_regression_model.pkl']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Assuming vectorizer and classification model 'clf' are already fitted and trained\n","\n","# Take a sample query\n","query = \"Comb\"\n","\n","# Debugging\n","print(f\"Query before prediction: {query}\")\n","\n","# Transform the query using the same TF-IDF vectorizer used for training the model\n","query_tfidf = tfidf_vectorizer.transform([query])\n","\n","\n","print(f\"TF-IDF for query: {query_tfidf.toarray()}\")\n","\n","\n","# Predict the category of the query\n","predicted_category = clf_lr.predict(query_tfidf)\n","\n","print(f\"The query belongs to the category: {predicted_category[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tng6MG9z4eOW","executionInfo":{"status":"ok","timestamp":1701577367625,"user_tz":480,"elapsed":153,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"f0dfe271-af8a-453e-a708-eb6bc12c3935"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Query before prediction: Comb\n","TF-IDF for query: [[0. 0. 0. ... 0. 0. 0.]]\n","The query belongs to the category: Hair Care: Brushes\n"]}]},{"cell_type":"markdown","source":["XGBoost Classifier"],"metadata":{"id":"GYTKDLJxGPRo"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","from sklearn.utils.class_weight import compute_sample_weight\n","import xgboost as xgb\n","import joblib\n","\n","# Assuming X and df are defined earlier in your code\n","\n","# Convert class labels to integers\n","y = df['Category']\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y)\n","# Save the LabelEncoder to a file\n","joblib.dump(label_encoder, 'label_encoder.pkl')\n","# Split the data\n","X_train, X_test, y_train_encoded, y_test = train_test_split(X, y_train_encoded, test_size=0.2, random_state=42)\n","\n","# Calculate sample weights\n","sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_encoded)\n","\n","# Train the XGBoost classifier with sample weights\n","clf_xg = xgb.XGBClassifier()\n","clf_xg.fit(X_train, y_train_encoded, sample_weight=sample_weights)\n","\n","# Evaluate the classifier\n","y_pred = clf_xg.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EW_8wx37Cr4","executionInfo":{"status":"ok","timestamp":1701743843483,"user_tz":480,"elapsed":215181,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"f2d6ab2d-e270-4b2f-c999-c88b28b25dec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7516556291390728\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","# Save the re-trained model\n","joblib.dump(clf_xg, 'xgb_model.pkl')\n","\n"],"metadata":{"id":"u71EYmdl1aBt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701744434303,"user_tz":480,"elapsed":679,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"925148e9-d64b-4e81-de57-a49fc49ef9b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['xgb_model.pkl']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","# Assuming X and y are defined and hold your features and labels\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Instantiate the Decision Tree Classifier\n","# You can manually set parameters if you wish, or use default settings\n","clf_dt = DecisionTreeClassifier(class_weight='balanced')\n","\n","# Fit the classifier on the training data\n","clf_dt.fit(X_train, y_train)\n","\n","# Save the trained model\n","joblib.dump(clf_dt, 'decision_tree_model.pkl')\n","\n","# Make predictions on the test set\n","y_pred = clf_dt.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOzyk2jYVF9Q","executionInfo":{"status":"ok","timestamp":1701635100704,"user_tz":480,"elapsed":3652,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"9f815f6e-7a16-48e5-f91a-6c675d899a00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6225165562913907\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","\n","y = df['Category']\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create and train the RandomForestClassifier\n","clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf_rf.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = clf_rf.predict(X_test)\n","\n","# Calculate Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Calculate Precision, Recall, and F1-Score\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Calculate Confusion Matrix\n","confusion = confusion_matrix(y_test, y_pred)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","print(\"Confusion Matrix:\")\n","print(confusion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3O3a-JEVGSE","executionInfo":{"status":"ok","timestamp":1701724494379,"user_tz":480,"elapsed":10015,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"ea98fb0f-946a-4ab2-9fca-35fe33c8f06a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.68\n","Precision: 0.69\n","Recall: 0.68\n","F1-Score: 0.65\n","Confusion Matrix:\n","[[ 5  0  0 ...  0  0  0]\n"," [ 0  2  0 ...  0  0  0]\n"," [ 0  0  2 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0 28  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create and train the RandomForestClassifier\n","clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf_rf.fit(X_train, y_train)\n","\n","# Make predictions and probability estimates\n","y_pred_rf = clf_rf.predict(X_test)\n","y_prob_rf = clf_rf.predict_proba(X_test)\n","\n","# Choose the positive class probability (for multi-class problems)\n","# Assuming your target variable is encoded with integers starting from 0\n","positive_class_index = 1  # Change this according to your problem\n","\n","# Calculate ROC-AUC score\n","roc_auc = roc_auc_score(y_test == positive_class_index, y_prob_rf[:, positive_class_index], multi_class='ovr', average='weighted')\n","\n","# Calculate Accuracy, Precision, Recall, and F1-Score\n","accuracy = accuracy_score(y_test, y_pred_rf)\n","precision = precision_score(y_test, y_pred_rf, average='weighted')\n","recall = recall_score(y_test, y_pred_rf, average='weighted')\n","f1 = f1_score(y_test, y_pred_rf, average='weighted')\n","\n","# Calculate Confusion Matrix\n","confusion = confusion_matrix(y_test, y_pred_rf)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n","\n","print(\"Confusion Matrix:\")\n","print(confusion)\n"],"metadata":{"id":"LbABUU_ap2Vc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model Ensembling by Voting mechanism"],"metadata":{"id":"uGMWuFeK6PbU"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Create an ensemble of classifiers using soft voting\n","ensemble_clf = VotingClassifier(estimators=[\n","    ('xg', clf_xg),\n","    ('lr', clf_lr)\n","   # ('svm', best_clf_svm),\n","    #('rf', clf_rf)\n","    #('dt', clf_dt)\n","], voting='soft')\n","\n","# Train the ensemble\n","ensemble_clf.fit(X_train, y_train)\n","\n","# Evaluate the ensemble\n","y_pred = ensemble_clf.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"gx1b8PAS6Puy","executionInfo":{"status":"error","timestamp":1701644609831,"user_tz":480,"elapsed":3031592,"user":{"displayName":"Sowmya Kuruba","userId":"00045548809830751852"}},"outputId":"bab81e38-c1c6-432c-c65e-ff99e4bf001e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-ad097af70d4e>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Evaluate the ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"soft\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         avg = np.average(\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights_not_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         )\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    830\u001b[0m                 \u001b[0;34m\"predict_proba is not available when  probability=False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             )\n","\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Create individual classifiers\n","clf_xg = xgb.XGBClassifier()\n","clf_lr = LogisticRegression()\n","best_clf_svm = SVC(class_weight='balanced', probability=True)  # Set probability=True\n","\n","# Create an ensemble of classifiers using soft voting\n","ensemble_clf = VotingClassifier(estimators=[\n","    ('xg', clf_xg),\n","    ('lr', clf_lr),\n","    ('svm', best_clf_svm)\n","], voting='soft')\n","\n","# Train the ensemble\n","ensemble_clf.fit(X_train, y_train)\n","\n","# Evaluate the ensemble\n","y_pred = ensemble_clf.predict(X_test)\n","\n","# Calculate Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Calculate Precision, Recall, and F1-Score\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Calculate Confusion Matrix\n","confusion = confusion_matrix(y_test, y_pred)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","print(\"Confusion Matrix:\")\n","print(confusion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeCgdqEVs15t","executionInfo":{"status":"ok","timestamp":1701727144366,"user_tz":480,"elapsed":353742,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"2170701e-304c-41b0-913c-0b45f9a44b58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.74\n","Precision: 0.75\n","Recall: 0.74\n","F1-Score: 0.72\n","Confusion Matrix:\n","[[ 3  0  0 ...  0  0  0]\n"," [ 0  1  0 ...  0  0  0]\n"," [ 0  0  1 ...  0  1  0]\n"," ...\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0 35  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","\n","# Split the data\n","y = df['Category']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Create individual classifiers\n","clf_xg = xgb.XGBClassifier()\n","clf_lr = LogisticRegression()\n","best_clf_svm = SVC(class_weight='balanced', probability=True)  # Set probability=True\n","\n","# Create an ensemble of classifiers using soft voting\n","ensemble_clf = VotingClassifier(estimators=[\n","    ('xg', clf_xg),\n","    ('lr', clf_lr),\n","    ('svm', best_clf_svm)\n","], voting='soft')\n","\n","# Train the ensemble\n","ensemble_clf.fit(X_train, y_train)\n","\n","# Evaluate the ensemble\n","y_pred = ensemble_clf.predict(X_test)\n","y_prob = ensemble_clf.predict_proba(X_test)\n","\n","# Choose the positive class probability (for multi-class problems)\n","# Assuming your target variable is encoded with integers starting from 0\n","positive_class_index = 1  # Change this according to your problem\n","\n","# Calculate ROC-AUC score\n","roc_auc = roc_auc_score(y_test == positive_class_index, y_prob[:, positive_class_index], multi_class='ovr', average='weighted')\n","\n","# Calculate Accuracy, Precision, Recall, and F1-Score\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Calculate Confusion Matrix\n","confusion = confusion_matrix(y_test, y_pred)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n","\n","print(\"Confusion Matrix:\")\n","print(confusion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"R-L5T90JqBf4","executionInfo":{"status":"error","timestamp":1702262074276,"user_tz":480,"elapsed":195,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"8c6a5596-b599-4e5e-e413-6b6fdc578ec5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e1ca5d41cdc8>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create individual classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf_xg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mclf_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_clf_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set probability=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aNBpP2hQu1X9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load the saved models"],"metadata":{"id":"2RJIPrF-yDNP"}},{"cell_type":"code","source":["from google.colab import drive\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","# 1. Load Saved Models\n","classification_model = joblib.load('xgb_model.pkl')\n","text_vectorizer = joblib.load('balanced_tfidf_vectorizer.pkl')\n","# Load the LabelEncoder\n","label_encoder = joblib.load('label_encoder.pkl')\n"],"metadata":{"id":"rWFp9oShxstC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Implement the Recommendation Logic and Test the Real time query"],"metadata":{"id":"sskJKmHvyPGR"}},{"cell_type":"code","source":["\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","label_encoder = LabelEncoder()\n","import joblib\n","\n","\n","\n","# 2. User Query\n","query = input(\"Enter your search query: \")\n","\n","# 3. Predict Category\n","query_tfidf = text_vectorizer.transform([query])\n","#predicted_category = classification_model.predict(query_tfidf)[0]\n","#print(f\"The query belongs to the category: {predicted_category}\")\n","\n","# 4. Load the DataFrame\n","df = pd.read_csv('Cleaned_Products_Data.csv')\n","\n","\n","label_encoder = LabelEncoder()\n","label_encoder.fit(df['Category'])\n","# Predict the category of the query\n","predicted_category_encoded = classification_model.predict(query_tfidf)\n","\n","# Decode the predicted category back to original category name\n","predicted_category = label_encoder.inverse_transform(predicted_category_encoded)\n","\n","print(f\"The query belongs to the category: {predicted_category[0]}\")\n","\n","\n","\n","# Generate TF-IDF matrix for the loaded data\n","X = text_vectorizer.transform(df['summary_lemmatized'])\n","\n","# 5. Filter Products by Predicted Category\n","filtered_df = df[df['Category'] == predicted_category[0]]\n","\n","\n","# 6. Compute Similarity\n","# Filter your TF-IDF matrix to only include vectors in the filtered_df\n","#target_tfidf_matrix = X[df['Category'] == predicted_category]\n","target_tfidf_matrix = X[df['Category'] == predicted_category[0]]\n","# Compute the cosine similarity scores\n","query_similarity_scores = cosine_similarity(query_tfidf, target_tfidf_matrix)\n","\n","# 7. Top-N Recommendations\n","N = 5  # Change N as needed\n","top_N_indices = np.argsort(query_similarity_scores[0])[-N:][::-1]\n","top_N_scores = query_similarity_scores[0][top_N_indices]\n","\n","top_N_recommendations = filtered_df.iloc[top_N_indices][['title', 'price']]\n","\n","# Show the top N recommendations\n","top_N_recommendations['similarity_score'] = top_N_scores\n","\n","from prettytable import PrettyTable\n","\n","# ... [rest of your code for computing top_N_recommendations] ...\n","\n","# Create a PrettyTable object\n","table = PrettyTable()\n","\n","# Define the column names\n","table.field_names = [\"Title\", \"Price\", \"Category\", \"Similarity Score\"]\n","\n","# Add rows to the table\n","for _, row in top_N_recommendations.iterrows():\n","    table.add_row([row['title'], row['price'], predicted_category, round(row['similarity_score'], 4)])\n","print(\"Top N recommendations with similarity scores:\")\n","print(table)\n","print(\"Top N recommendations:\")\n","print(top_N_recommendations)\n","top_N_recommendations.to_csv('reco_data.csv', index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nRtqHVL1RYE","outputId":"737872a2-4ef5-4f6d-b3ab-dfd81b889f1e","executionInfo":{"status":"ok","timestamp":1701744926297,"user_tz":480,"elapsed":61924,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your search query: Glo Minerals Moist Hydration Mist 2.0 oz\n","The query belongs to the category: Face Care: Serums, Mists & Toners\n","Top N recommendations with similarity scores:\n","+--------------------------------------------------------------------------------------------------------+---------+---------------------------------------+------------------+\n","|                                                 Title                                                  |  Price  |                Category               | Similarity Score |\n","+--------------------------------------------------------------------------------------------------------+---------+---------------------------------------+------------------+\n","|                                Glo Minerals Moist Hydration Mist 2.0 oz                                | $22.00  | ['Face Care: Serums, Mists & Toners'] |      0.5482      |\n","|                             glo Minerals Revive Hydration Mist, 2 fl. oz.                              | $20.00  | ['Face Care: Serums, Mists & Toners'] |      0.3331      |\n","|                               NEUMA neuSmooth Illuminating Mist, 2.5 oz.                               | $22.00  | ['Face Care: Serums, Mists & Toners'] |      0.245       |\n","|   Mario Badescu Spritz Mist and Glow Facial Spray Collection, 3 Piece Set - Lavender, Cucumber, Rose   | $21.00  | ['Face Care: Serums, Mists & Toners'] |      0.2301      |\n","| NuFACE Optimizing Mist | Anti-Aging + Hydrating with Aloe Vera, Hyaluronic Acid and Botanical Extracts | $29.00  | ['Face Care: Serums, Mists & Toners'] |      0.1827      |\n","+--------------------------------------------------------------------------------------------------------+---------+---------------------------------------+------------------+\n","Top N recommendations:\n","                                                  title    price  \\\n","24             Glo Minerals Moist Hydration Mist 2.0 oz  $22.00    \n","1409      glo Minerals Revive Hydration Mist, 2 fl. oz.  $20.00    \n","1743         NEUMA neuSmooth Illuminating Mist, 2.5 oz.  $22.00    \n","3130  Mario Badescu Spritz Mist and Glow Facial Spra...  $21.00    \n","2874  NuFACE Optimizing Mist | Anti-Aging + Hydratin...  $29.00    \n","\n","      similarity_score  \n","24            0.548184  \n","1409          0.333069  \n","1743          0.244955  \n","3130          0.230069  \n","2874          0.182731  \n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","import joblib\n","\n","# ... [rest of your imports and setup] ...\n","\n","# 2. User Query\n","query = input(\"Enter your search query: \")\n","\n","# 3. Predict Category\n","query_tfidf = text_vectorizer.transform([query])\n","\n","# 4. Load the DataFrame\n","df = pd.read_csv('Cleaned_Products_Data.csv')\n","\n","# Initialize and fit LabelEncoder\n","label_encoder = LabelEncoder()\n","label_encoder.fit(df['Category'])\n","\n","# Predict the category of the query\n","predicted_category_encoded = classification_model.predict(query_tfidf)\n","\n","# Decode the predicted category back to original category name\n","predicted_category = label_encoder.inverse_transform(predicted_category_encoded)\n","print(f\"The query belongs to the category: {predicted_category[0]}\")\n","\n","# Generate TF-IDF matrix for the loaded data\n","X = text_vectorizer.transform(df['summary_lemmatized'])\n","\n","# 5. Filter Products by Predicted Category\n","filtered_df = df[df['Category'] == predicted_category[0]]\n","\n","# 6. Compute Similarity\n","# Filter your TF-IDF matrix to only include vectors in the filtered_df\n","target_tfidf_matrix = X[df['Category'] == predicted_category[0]]\n","\n","# Compute the cosine similarity scores\n","query_similarity_scores = cosine_similarity(query_tfidf, target_tfidf_matrix)\n","\n","# 7. Top-N Recommendations\n","N = 6  # Change N as needed\n","top_N_indices = np.argsort(query_similarity_scores[0])[-N:][::-1]\n","top_N_scores = query_similarity_scores[0][top_N_indices]\n","\n","# Exclude the user query from recommendations\n","# Assuming 'title' column contains product titles\n","top_N_recommendations = filtered_df.iloc[top_N_indices]\n","top_N_recommendations = top_N_recommendations[top_N_recommendations['title'].str.lower() != query.lower()][['title', 'price']]\n","\n","# Show the top N recommendations\n","top_N_recommendations['similarity_score'] = top_N_scores[:len(top_N_recommendations)]\n","\n","from prettytable import PrettyTable\n","\n","# Create a PrettyTable object\n","table = PrettyTable()\n","\n","# Define the column names\n","table.field_names = [\"Title\", \"Price\", \"Category\", \"Similarity Score\"]\n","\n","# Add rows to the table\n","for _, row in top_N_recommendations.iterrows():\n","    table.add_row([row['title'], row['price'], predicted_category[0], round(row['similarity_score'], 4)])\n","print(\"Top N recommendations with similarity scores:\")\n","print(table)\n","print(\"Top N recommendations:\")\n","print(top_N_recommendations)\n","top_N_recommendations.to_csv('reco_data.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm10FN4q6cVe","executionInfo":{"status":"ok","timestamp":1701745147657,"user_tz":480,"elapsed":12687,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"ffc1056b-42de-436c-c53d-f7581fd11a82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your search query: Glo Minerals Moist Hydration Mist 2.0 oz\n","The query belongs to the category: Face Care: Serums, Mists & Toners\n","Top N recommendations with similarity scores:\n","+--------------------------------------------------------------------------------------------------------+---------+-----------------------------------+------------------+\n","|                                                 Title                                                  |  Price  |              Category             | Similarity Score |\n","+--------------------------------------------------------------------------------------------------------+---------+-----------------------------------+------------------+\n","|                             glo Minerals Revive Hydration Mist, 2 fl. oz.                              | $20.00  | Face Care: Serums, Mists & Toners |      0.5482      |\n","|                               NEUMA neuSmooth Illuminating Mist, 2.5 oz.                               | $22.00  | Face Care: Serums, Mists & Toners |      0.3331      |\n","|   Mario Badescu Spritz Mist and Glow Facial Spray Collection, 3 Piece Set - Lavender, Cucumber, Rose   | $21.00  | Face Care: Serums, Mists & Toners |      0.245       |\n","| NuFACE Optimizing Mist | Anti-Aging + Hydrating with Aloe Vera, Hyaluronic Acid and Botanical Extracts | $29.00  | Face Care: Serums, Mists & Toners |      0.2301      |\n","|                              Osmosis Skincare Clear Plus+ Activating Mist                              | $30.00  | Face Care: Serums, Mists & Toners |      0.1827      |\n","+--------------------------------------------------------------------------------------------------------+---------+-----------------------------------+------------------+\n","Top N recommendations:\n","                                                  title    price  \\\n","1409      glo Minerals Revive Hydration Mist, 2 fl. oz.  $20.00    \n","1743         NEUMA neuSmooth Illuminating Mist, 2.5 oz.  $22.00    \n","3130  Mario Badescu Spritz Mist and Glow Facial Spra...  $21.00    \n","2874  NuFACE Optimizing Mist | Anti-Aging + Hydratin...  $29.00    \n","2614       Osmosis Skincare Clear Plus+ Activating Mist  $30.00    \n","\n","      similarity_score  \n","1409          0.548184  \n","1743          0.333069  \n","3130          0.244955  \n","2874          0.230069  \n","2614          0.182731  \n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.metrics import classification_report\n","\n","# Load the saved model\n","ensemble_model = joblib.load('ensemble_model.pkl')\n","\n","# Assuming you have your test data and labels (X_test, y_test)\n","# Replace X_test and y_test with your actual test data and labels\n","\n","# Make predictions\n","y_pred = ensemble_model.predict(X_test)\n","\n","# Get the classification report\n","class_report = classification_report(y_test, y_pred)\n","\n","# Print the classification report\n","print(class_report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5EevHRwuTBp","executionInfo":{"status":"ok","timestamp":1702262175998,"user_tz":480,"elapsed":810,"user":{"displayName":"Anitha Balachandran","userId":"02665378724772272165"}},"outputId":"5e50877f-2887-4ae9-a5b9-9af6d4852e27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                 precision    recall  f1-score   support\n","\n","         Baby Care: Cleansers, Creams & Lotions       1.00      0.57      0.73         7\n","     Beard & Mustache Care: Oils, Serums & Gels       0.00      0.00      0.00         7\n","                      Body Care: Butters & Oils       0.00      0.00      0.00         5\n","                           Body Care: Cleansers       0.00      0.00      0.00        18\n","                 Body Care: Exfoliants & Scrubs       0.00      0.00      0.00         6\n","                     Body Care: Lotions & Mists       0.80      0.15      0.26        26\n","                           Body Care: Mini Kits       0.00      0.00      0.00         1\n","             Body Care: Neck Creams & Ointments       0.00      0.00      0.00         1\n","                 Body Care: Tools & Accessories       0.00      0.00      0.00         5\n","          Eye Care: Brow Gels, Serums & Pencils       0.00      0.00      0.00         2\n","         Eye Care: Brow Gels, Serums & Pencils        0.00      0.00      0.00         4\n","                          Eye Care: Eye Shadows       1.00      0.17      0.29         6\n","                            Eye Care: Eyeliners       0.00      0.00      0.00         6\n","                              Eye Care: Mascara       1.00      0.08      0.15        12\n","                      Eye Care: Serums & Creams       1.00      0.50      0.67        24\n","                  Eye Care: Tools & Accessories       0.00      0.00      0.00         2\n","                           Face Care: Cleansers       1.00      0.35      0.52        23\n","                       Face Care: Masks & Peels       0.00      0.00      0.00        24\n","              Face Care: Moisturizers & Creams        0.92      0.22      0.35        55\n","                              Face Care: Scrubs       0.00      0.00      0.00         5\n","              Face Care: Serums, Mists & Toners       0.20      0.89      0.32        61\n","                Face Care: SkinCare/Makeup Kits       0.00      0.00      0.00         6\n","             Foot Care: Foot Creams and Lotions       0.00      0.00      0.00         3\n","                         Hair Care: Accessories       0.00      0.00      0.00         1\n","                             Hair Care: Brushes       0.00      0.00      0.00         6\n","                        Hair Care: Conditioners       1.00      0.52      0.69        46\n","                      Hair Care: Gels & Pomades       0.94      0.38      0.54        42\n","                            Hair Care: Hair Dye       0.00      0.00      0.00         2\n","                               Hair Care: Masks       0.00      0.00      0.00        21\n","                       Hair Care: Oils & Serums       0.00      0.00      0.00        16\n","          Hair Care: Shampoo & Conditioner Kits       0.00      0.00      0.00         6\n","                            Hair Care: Shampoos       1.00      0.76      0.86        50\n","                      Hair Care: Spray & Mousse       0.94      0.50      0.65        58\n","                       Hair Care: Styling Tools       1.00      0.77      0.87        39\n","Hand Care: Creams, Lotions , Cleansers & Gloves       1.00      0.21      0.35        14\n","                            Lip Care: Lip Gloss       0.00      0.00      0.00         7\n","                           Lip Care: Lip Liners       0.00      0.00      0.00         2\n","                       Lip Care: Serums & Balms       1.00      0.22      0.36         9\n","                     Lip Care: Sticks & Crayons       1.00      0.20      0.33        10\n","         Makeup: Blush, Highlighters & Shimmers       0.00      0.00      0.00         9\n","          Makeup: Color Correctors & Concealers       0.00      0.00      0.00         6\n","                Makeup: Foundations & CC Creams       1.00      0.06      0.11        17\n","                     Makeup: Powders & Bronzers       1.00      0.17      0.29        12\n","                                Makeup: Primers       0.00      0.00      0.00         6\n","                   Makeup: Remover Oils & Balms       0.00      0.00      0.00         9\n","                    Makeup: Tools & Accessories       0.00      0.00      0.00         9\n","                           Nail Care: Base Coat       0.00      0.00      0.00         2\n","                     Nail Care: Color Polishes        0.92      0.80      0.86        30\n","                 Nail Care: Oils, Creams & Gels       0.00      0.00      0.00         8\n","                 Nail Care: Tools & Accessories       0.00      0.00      0.00         2\n","                            Nail Care: Top Coat       0.00      0.00      0.00         2\n","            Oral Care: Mouthwashes & Toothpaste       0.00      0.00      0.00         4\n","                 Oral Care: Tools & Accessories       0.00      0.00      0.00         1\n","                 Personal Care: Home Fragrances       0.00      0.00      0.00        11\n","            Personal Care: Perfumes & Deodrants       0.20      1.00      0.34        77\n"," Personal Care: Shaving Creams, Lotions & Gels        0.88      0.70      0.78        20\n","     Personal Care: Shaving Tools & Accessories       1.00      0.25      0.40         8\n","                   Personal Care: Water Bottles       0.00      0.00      0.00         2\n","                          Skin Care: Sunscreens       1.00      0.47      0.64        30\n","              Skin Care: Supplements & Oinments       0.00      0.00      0.00         3\n","\n","                                       accuracy                           0.41       906\n","                                      macro avg       0.35      0.17      0.19       906\n","                                   weighted avg       0.60      0.41      0.40       906\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}